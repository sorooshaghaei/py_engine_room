{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e997e20e",
   "metadata": {},
   "source": [
    "# 00 Overview\n",
    "\n",
    "\n",
    "\n",
    "Goal: learn one reusable repo architecture and apply it to any project type.\n",
    "\n",
    "\n",
    "\n",
    "## Learning checklist\n",
    "\n",
    "- [ ] I can explain why we use `src/` layout.\n",
    "\n",
    "- [ ] I can explain why `__init__.py` should be minimal.\n",
    "\n",
    "- [ ] I can describe `config -> steps -> artifacts -> logs -> metrics`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9783980",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "\n",
    "class PipelineContext:\n",
    "\n",
    "    config: dict[str, Any]\n",
    "\n",
    "    artifacts: dict[str, Any] = field(default_factory=dict)\n",
    "\n",
    "    metrics: dict[str, float] = field(default_factory=dict)\n",
    "\n",
    "\n",
    "\n",
    "ctx = PipelineContext(config={\"run_name\": \"demo\"})\n",
    "\n",
    "ctx.artifacts[\"example\"] = \"outputs/demo/result.txt\"\n",
    "\n",
    "ctx.metrics[\"quality\"] = 1.0\n",
    "\n",
    "ctx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e1e596",
   "metadata": {},
   "source": [
    "## Active recall\n",
    "\n",
    "Without looking back, write 3 reasons that explicit artifacts improve team collaboration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96aee4d",
   "metadata": {},
   "source": [
    "## Practice Lab\n",
    "\n",
    "1. Change `run_name` and add one new metric.\n",
    "2. Explain in one sentence why artifacts and metrics should both exist.\n",
    "3. Re-run this cell and verify your metric updates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f38d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "practice_ctx = {\"config\": {\"run_name\": \"practice-run\"}, \"artifacts\": {}, \"metrics\": {}}\n",
    "practice_ctx[\"artifacts\"][\"report\"] = \"outputs/practice-run/report.txt\"\n",
    "practice_ctx[\"metrics\"][\"records_processed\"] = 10.0\n",
    "practice_ctx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d49c4b",
   "metadata": {},
   "source": [
    "## Active Learning Practice\n",
    "\n",
    "1. Recall sprint (2 minutes): write the pipeline stages from memory.\n",
    "2. Retrieval drill: complete the ordered flow and verify it.\n",
    "3. Transfer drill: adapt one pipeline rule for app/library/research variants.\n",
    "4. Reflection: note one concept you forgot and review it tomorrow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb95311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_flow() -> list[str]:\n",
    "    \"\"\"Return the canonical stage order.\"\"\"\n",
    "    return [\"config\", \"steps\", \"artifacts\", \"logs\", \"metrics\"]\n",
    "\n",
    "flow = pipeline_flow()\n",
    "is_correct = flow == [\"config\", \"steps\", \"artifacts\", \"logs\", \"metrics\"]\n",
    "adaptations = {\n",
    "    \"app\": \"use a thin CLI entrypoint\",\n",
    "    \"library\": \"keep pipeline optional and API-first\",\n",
    "    \"research\": \"extract repeated notebook logic into src\",\n",
    "}\n",
    "{\"flow\": flow, \"is_correct\": is_correct, \"adaptations\": adaptations}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
