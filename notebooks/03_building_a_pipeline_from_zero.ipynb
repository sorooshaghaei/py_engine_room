{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 Building A Pipeline From Zero\n",
    "\n",
    "This notebook builds the same scaffold used in all templates."
   ],
   "id": "c133c1bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Protocol\n",
    "\n",
    "@dataclass\n",
    "class PipelineContext:\n",
    "    config: dict[str, Any]\n",
    "    artifacts: dict[str, Any] = field(default_factory=dict)\n",
    "    metrics: dict[str, float] = field(default_factory=dict)\n",
    "\n",
    "class PipelineStep(Protocol):\n",
    "    name: str\n",
    "    def run(self, ctx: PipelineContext) -> PipelineContext: ...\n",
    "\n",
    "class AddArtifactStep:\n",
    "    name = \"add_artifact\"\n",
    "    def run(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        ctx.artifacts[\"result\"] = \"outputs/demo/result.txt\"\n",
    "        return ctx\n",
    "\n",
    "class AddMetricsStep:\n",
    "    name = \"add_metrics\"\n",
    "    def run(self, ctx: PipelineContext) -> PipelineContext:\n",
    "        ctx.metrics[\"steps\"] = 2.0\n",
    "        return ctx\n",
    "\n",
    "def run_pipeline(config: dict[str, Any], steps: list[PipelineStep]) -> PipelineContext:\n",
    "    ctx = PipelineContext(config=config)\n",
    "    for step in steps:\n",
    "        ctx = step.run(ctx)\n",
    "    return ctx\n",
    "\n",
    "run_pipeline({\"run_name\": \"demo\"}, [AddArtifactStep(), AddMetricsStep()])"
   ],
   "id": "6bc22aff"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptation practice\n",
    "Apply the same steps pattern to: an app, a library utility, and a research notebook flow.\n",
    "Keep the contract (`run(ctx) -> ctx`) unchanged."
   ],
   "id": "ac28ccf9"
  },
  {
   "cell_type": "markdown",
   "id": "f3dadf91",
   "metadata": {},
   "source": [
    "## Practice Lab\n",
    "\n",
    "Add one new step that updates metrics and run the pipeline with three steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3147118e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import Any, Protocol\n",
    "\n",
    "@dataclass\n",
    "class Ctx:\n",
    "    config: dict[str, Any]\n",
    "    artifacts: dict[str, Any] = field(default_factory=dict)\n",
    "    metrics: dict[str, float] = field(default_factory=dict)\n",
    "\n",
    "class Step(Protocol):\n",
    "    name: str\n",
    "    def run(self, ctx: Ctx) -> Ctx: ...\n",
    "\n",
    "class AddArtifact:\n",
    "    name = \"artifact\"\n",
    "    def run(self, ctx: Ctx) -> Ctx:\n",
    "        ctx.artifacts[\"path\"] = \"outputs/practice/result.txt\"\n",
    "        return ctx\n",
    "\n",
    "class AddMetric:\n",
    "    name = \"metric\"\n",
    "    def run(self, ctx: Ctx) -> Ctx:\n",
    "        ctx.metrics[\"quality\"] = 0.9\n",
    "        return ctx\n",
    "\n",
    "class AddDuration:\n",
    "    name = \"duration\"\n",
    "    def run(self, ctx: Ctx) -> Ctx:\n",
    "        ctx.metrics[\"duration_seconds\"] = 0.01\n",
    "        return ctx\n",
    "\n",
    "def run(steps: list[Step]) -> Ctx:\n",
    "    ctx = Ctx(config={\"run_name\": \"practice\"})\n",
    "    for step in steps:\n",
    "        ctx = step.run(ctx)\n",
    "    return ctx\n",
    "\n",
    "run([AddArtifact(), AddMetric(), AddDuration()])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af96d6a5",
   "metadata": {},
   "source": [
    "## Active Learning Practice\n",
    "\n",
    "1. Add one new step role from memory.\n",
    "2. Validate your order with the checker.\n",
    "3. Move one step and predict what breaks.\n",
    "4. State one reason context passing beats global state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c193bca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_order = [\"load_config\", \"build_features\", \"train\", \"evaluate\", \"report\"]\n",
    "\n",
    "def validate_order(order: list[str]) -> dict[str, bool]:\n",
    "    return {\n",
    "        \"starts_with_config\": bool(order) and order[0] == \"load_config\",\n",
    "        \"ends_with_report\": bool(order) and order[-1] == \"report\",\n",
    "        \"has_evaluate_after_train\": order.index(\"evaluate\") > order.index(\"train\"),\n",
    "    }\n",
    "\n",
    "checks = validate_order(candidate_order)\n",
    "{\"order\": candidate_order, \"checks\": checks, \"all_good\": all(checks.values())}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
